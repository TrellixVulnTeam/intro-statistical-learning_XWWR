{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic ML model\n",
    "\n",
    "This notebook will guide you through my process of creating a ML model to predict who died and who survived the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/pedro/github/intro-statistical-learning/data/titanic/train.csv\")\n",
    "submission_test_set = pd.read_csv(\"/Users/pedro/github/intro-statistical-learning/data/titanic/test.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During data exploration, proxy class seemed to be a rather influential feature, thus I want to make sure these are stratified proportionally in my training and test groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state = 69)\n",
    "for train_index, test_index in split.split(data, data.Pclass):\n",
    "        strat_train_set = data.loc[train_index]\n",
    "        strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the proportions were maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.553073\n",
       "1    0.240223\n",
       "2    0.206704\n",
       "Name: Pclass, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set.Pclass.value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.550562\n",
       "1    0.242978\n",
       "2    0.206461\n",
       "Name: Pclass, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set.Pclass.value_counts() /len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.551066\n",
       "1    0.242424\n",
       "2    0.206510\n",
       "Name: Pclass, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original proportions\n",
    "data.Pclass.value_counts() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja! Alles gut!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Millet, Mr. Francis Davis</td>\n",
       "      <td>male</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13509</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E38</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Stanley, Mr. Edward Roland</td>\n",
       "      <td>male</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 45380</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Jardin, Mr. Jose Neto</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101305</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Newsom, Miss. Helen Monypeny</td>\n",
       "      <td>female</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11752</td>\n",
       "      <td>26.2833</td>\n",
       "      <td>D47</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>851</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Master. Sigvard Harald Elias</td>\n",
       "      <td>male</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Olsson, Mr. Nils Johan Goransson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347464</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>304</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Keane, Miss. Nora A</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226593</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>E101</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Betros, Mr. Tannous</td>\n",
       "      <td>male</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2648</td>\n",
       "      <td>4.0125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Richards, Master. George Sibley</td>\n",
       "      <td>male</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29106</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                     Name  \\\n",
       "456          457         0       1                Millet, Mr. Francis Davis   \n",
       "494          495         0       3               Stanley, Mr. Edward Roland   \n",
       "611          612         0       3                    Jardin, Mr. Jose Neto   \n",
       "136          137         1       1             Newsom, Miss. Helen Monypeny   \n",
       "850          851         0       3  Andersson, Master. Sigvard Harald Elias   \n",
       "..           ...       ...     ...                                      ...   \n",
       "281          282         0       3         Olsson, Mr. Nils Johan Goransson   \n",
       "303          304         1       2                      Keane, Miss. Nora A   \n",
       "882          883         0       3             Dahlberg, Miss. Gerda Ulrika   \n",
       "378          379         0       3                      Betros, Mr. Tannous   \n",
       "831          832         1       2          Richards, Master. George Sibley   \n",
       "\n",
       "        Sex    Age  SibSp  Parch              Ticket     Fare Cabin Embarked  \n",
       "456    male  65.00      0      0               13509  26.5500   E38        S  \n",
       "494    male  21.00      0      0           A/4 45380   8.0500   NaN        S  \n",
       "611    male    NaN      0      0  SOTON/O.Q. 3101305   7.0500   NaN        S  \n",
       "136  female  19.00      0      2               11752  26.2833   D47        S  \n",
       "850    male   4.00      4      2              347082  31.2750   NaN        S  \n",
       "..      ...    ...    ...    ...                 ...      ...   ...      ...  \n",
       "281    male  28.00      0      0              347464   7.8542   NaN        S  \n",
       "303  female    NaN      0      0              226593  12.3500  E101        Q  \n",
       "882  female  22.00      0      0                7552  10.5167   NaN        S  \n",
       "378    male  20.00      0      0                2648   4.0125   NaN        C  \n",
       "831    male   0.83      1      1               29106  18.7500   NaN        S  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create a copy of our training set to manipulate it as we wish\n",
    "df = strat_train_set.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations\n",
    "Now let's deal with nans, scaling, and encoding our ordinal and categorical variables so that we can later test out different algorithms with any of our features.\n",
    "\n",
    "This next block is a demonstration of how encoders are used. However we will group all our encoding processes in a pipeline (see next block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_cat = df[['Sex']]\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "sex_1hot = cat_encoder.fit_transform(df_cat)\n",
    "\n",
    "print(sex_1hot.shape)\n",
    "cat_encoder.categories_\n",
    "#We have created a sparse matrix shape: 712,2 with female and male as the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I'm trying out imputing on ordinal data\n",
    "\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "embarked_imp = imp.fit_transform(df[['Embarked']])\n",
    "type(embarked_imp)\n",
    "\n",
    "#But how do I integrate the ndarray to my df???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "\n",
    "#First we create the pipeline for numerical variables\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "#Now we create the full pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "num_att = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_att = ['Sex']\n",
    "ord_att = ['Pclass']\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_att),\n",
    "    #('cat_imp', SimpleImputer(missing_values = np.nan, strategy='most_frequent'), cat_att),\n",
    "    ('cat', OneHotEncoder(), cat_att),\n",
    "    ('ord', OrdinalEncoder(), ord_att)\n",
    "])\n",
    "\n",
    "df_prepd = full_pipeline.fit_transform(df)\n",
    "\n",
    "#Couldn't fit Embarked because of its NaN. Follow the link for info on how to impute categorical variables to most frequent\n",
    "# https://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_prepd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_classifier = RandomForestClassifier()\n",
    "forest_classifier.fit(df_prepd, df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's cross validate our model using only the training set folded in 5\n",
    "\n",
    "So the set is split into 5 subsets, each subset is predicted by the other 4 subsets and we calculate how accurate the predictions were (as a percentage of correct classifications).\n",
    "\n",
    "cv defines the number of folds. I went for 5 cause its not a huge data set and its the default, but I'm not sure what the best number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(forest_classifier, df_prepd, df.Survived,\n",
    "                        scoring = 'accuracy', cv = 5)\n",
    "\n",
    "# Follow this link to check out other scoring methods you can use with cross validation\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.81118881 0.87412587 0.76923077 0.80985915 0.78014184] \n",
      " Mean:  0.8089092906893327 \n",
      " Standard Deviation:  0.03650000621016738\n"
     ]
    }
   ],
   "source": [
    "print('Scores: ', scores, '\\n Mean: ', scores.mean(), '\\n Standard Deviation: ', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems quite promising but we should compare these numbers to other models or tweaks to the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can save this model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest_classifier_titanic_woEmbark.pkl']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(forest_classifier, 'forest_classifier_titanic_woEmbark.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our test set prepared for this model but that should come much later.\n",
    "test_prepd = full_pipeline.fit_transform(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 4, 6],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid =[\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6]},\n",
    "    {'bootstrap':[False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "for_class_2 = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(for_class_2, param_grid, cv=5,\n",
    "                          scoring='accuracy', return_train_score = True)\n",
    "\n",
    "grid_search.fit(df_prepd, df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 10}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776685393258427 {'max_features': 2, 'n_estimators': 3}\n",
      "0.8103932584269663 {'max_features': 2, 'n_estimators': 10}\n",
      "0.8146067415730337 {'max_features': 2, 'n_estimators': 30}\n",
      "0.7808988764044944 {'max_features': 4, 'n_estimators': 3}\n",
      "0.8103932584269663 {'max_features': 4, 'n_estimators': 10}\n",
      "0.8089887640449438 {'max_features': 4, 'n_estimators': 30}\n",
      "0.8061797752808989 {'max_features': 6, 'n_estimators': 3}\n",
      "0.8202247191011236 {'max_features': 6, 'n_estimators': 10}\n",
      "0.8160112359550562 {'max_features': 6, 'n_estimators': 30}\n",
      "0.773876404494382 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.7963483146067416 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.7879213483146067 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.8061797752808989 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.8047752808988764 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.7991573033707865 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "for x, y in zip(results['mean_test_score'], results['params']):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541899441340782"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 10)\n",
    "\n",
    "model.fit(df_prepd, df.Survived)\n",
    "predictions = model.predict(test_prepd)\n",
    "\n",
    "(strat_test_set.Survived==predictions).sum()/len(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was able to predict the test set with 75% accuracy. Not bad!\n",
    "\n",
    "# Final fit\n",
    "\n",
    "Now we have to fit our model to all the data that is available to us, pipeline the submission test set provided by kaggle and run predictions on it. Finally, foru our submission we have to create a csv file with two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather data\n",
    "full_train = data.copy()\n",
    "\n",
    "#Pipeline transform both sets\n",
    "full_train_prepd = full_pipeline.fit_transform(full_train)\n",
    "submission_set_prepd = full_pipeline.fit_transform(submission_test_set)\n",
    "\n",
    "#Fit model\n",
    "model.fit(full_train_prepd, full_train.Survived)\n",
    "preds = model.predict(submission_set_prepd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         1\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put together in a Data Frame\n",
    "submission_df = pd.DataFrame({'PassengerId': submission_test_set.PassengerId,\n",
    "                             'Survived': preds})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we just have to save our DF as a csv file and we're ready to upload!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
